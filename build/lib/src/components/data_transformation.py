import os
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import   OneHotEncoder
from src.logger import logging
from src.exception import CustomException 
import sys
import math
class DataTransform():
    '''
    ## This class is responsible for data transformation and getting scaling parameter.

    ### Arguments:
        - qid: str
    
    ### Description:
        1. Checks if data is loaded and validated
        2. Scales data
        3. Splits data into train and test
        4. Saves data
    
    ### Functions:
        - get_scaling_parameter(): Returns scaling parameter
    '''
    def __init__(self, qid: str):
        self.qid = qid
        self.DATA_PATH = './data'
        self.PATH_X = os.path.join(self.DATA_PATH, self.qid, 'X.npy')
        self.PATH_Y = os.path.join(self.DATA_PATH, self.qid, 'Y.npy')
        self.nI,self.nQ,self.mean_I,self.mean_Q = None,None,None,None
        self.load_data()
        self.scale_transform()
        self.split_data()
        self.save_data()
    def load_data(self):
        try:
            self.X = np.load(self.PATH_X)
            self.Y = np.load(self.PATH_Y)
            logging.info('Data loaded for {}'.format(self.qid))
        except Exception as e:
            logging.error('Data loading failed for {}'.format(self.qid))
            raise CustomException(e, sys)
    
    def scale_transform(self):
        
        #Convert Y into one hot encoding
        try:
            encoder = OneHotEncoder()
            one_hot_encoded = encoder.fit_transform(self.Y.reshape(-1, 1))
            self.Y_OneHot = one_hot_encoded.toarray()
            if self.Y_OneHot.shape[1] == 2:
                self.Y_OneHot = np.concatenate((self.Y_OneHot, np.zeros((self.Y_OneHot.shape[0], 1))), axis=1)
                logging.info('Y has only 2 classes, adding extra dimension.....')
            logging.info('One-Hot encoding of Y for {} done' .format(self.qid))
        except Exception as e:
            logging.error('One-Hot encoding of Y failed for {}'.format(self.qid))
            raise CustomException(e, sys)


        #Find mean of X
        self.mean_I, self.mean_Q = -np.mean(self.X,axis=0).astype(int)
        logging.info('Moving parameter for {} is [{},{}]'.format(self.qid, self.mean_I, self.mean_Q))

        #Moving mean of X
        self.X[:,0]+= self.mean_I
        self.X[:,1]+= self.mean_Q

        #Get max of I and Q
        self.max_I = max(abs(self.X[:,0].max()), abs(self.X[:,0].min()))
        self.max_Q = max(abs(self.X[:,1].max()), abs(self.X[:,1].min()))
        self.nI = int(math.ceil(math.log2(self.max_I)))
        self.nQ = int(math.ceil(math.log2(self.max_Q)))
        logging.info('Scaling parameter for {} is [{},{}]'.format(self.qid, self.nI, self.nQ))

        #Scale X
        self.X[:,0]=(self.X[:,0]+(2**self.nI)-1)/(2**(self.nI+1))
        self.X[:,1]=(self.X[:,1]+(2**self.nQ)-1)/(2**(self.nQ+1))

    # split data into train and test
    def split_data(self):
        try:
            self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(self.X, self.Y_OneHot, test_size=0.4, random_state=9)
            logging.info('Data split for {} done'.format(self.qid))
        except Exception as e:
            logging.error('Data split failed for {}'.format(self.qid))
            raise CustomException(e, sys)
    
    # saves the data
    def save_data(self):
        try:
            np.save(os.path.join(self.DATA_PATH, self.qid, 'X_train.npy'), self.X_train)
            np.save(os.path.join(self.DATA_PATH, self.qid, 'X_test.npy'), self.X_test)
            np.save(os.path.join(self.DATA_PATH, self.qid, 'Y_train.npy'), self.Y_train)
            np.save(os.path.join(self.DATA_PATH, self.qid, 'Y_test.npy'), self.Y_test)
            logging.info('Scaled data saved for {}'.format(self.qid))
        except Exception as e:
            logging.error('Scaled data saving failed for {}'.format(self.qid))
            raise CustomException(e, sys)
    
    def getScalingParameter(self) -> tuple :
        '''
        ## This function returns the scaling parameter generated by DataTransformer instance.
        ### Arguments:
            None
        ### Returns:
            tuple: (nI, nQ, mean_I, mean_Q)
        '''
        return self.nI, self.nQ, self.mean_I, self.mean_Q


        



        
    

    
